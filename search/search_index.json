{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Team 5152 Robot Code Documentation","text":"<p>Welcome to the comprehensive documentation for Team 5152's robot code.</p> <p>If you are starting the new season from scratch, checkout the quickstart guide</p> <p>Javadocs can be found here</p>"},{"location":"quickstart/","title":"Robot Quickstart Guide","text":"<p>This guide provides step-by-step instructions for configuring and tuning your robot's swerve drive system.</p>"},{"location":"quickstart/#1-swerve-drive-configuration","title":"1. Swerve Drive Configuration","text":""},{"location":"quickstart/#11-can-id-management","title":"1.1 CAN ID Management","text":"<p>Important: Proper CAN ID management is critical for reliable robot operation Before beginning any swerve configuration, verify all CAN IDs:</p> <ol> <li> <p>Check current CAN IDs in <code>Constants.java</code> under <code>CanId</code>:    <pre><code>public static class CanId {\n    public static final int FRONT_LEFT_DRIVE_MTR_CAN_ID = 1;\n    public static final int FRONT_LEFT_STEER_MTR_CAN_ID = 2;\n    public static final int FRONT_LEFT_STEER_CAN_CODER_CAN_ID = 3;\n    // ... etc\n}\n</code></pre></p> </li> <li> <p>If your physical devices have different IDs:</p> <ul> <li>DO NOT change the IDs in code</li> <li>Use Phoenix Tuner X to update the device IDs to match the code</li> <li>This maintains backwards compatibility with previous configurations</li> <li>Helps prevent confusion when sharing code or reverting changes</li> </ul> </li> <li> <p>Best Practices:</p> <ul> <li>Keep a CAN ID spreadsheet/document for your team</li> <li>Label physical devices with their CAN IDs</li> <li>Use Phoenix Tuner X's network view to verify all devices are visible</li> <li>Test communication with each device before proceeding</li> </ul> </li> <li> <p>Common Issues:</p> <ul> <li>If devices aren't showing up, check CAN termination resistors</li> <li>Verify firmware versions are up to date</li> <li>Ensure power and CAN wire connections are secure</li> </ul> </li> </ol>"},{"location":"quickstart/#12-new-season-setup","title":"1.2 New Season Setup","text":"<p>When starting a new season: 1. Copy the previous year's tuner constants file (e.g., <code>TunerConstants2023.java</code>) 2. Rename it to match the new year (e.g., <code>TunerConstants2024.java</code>) 3. Update the class name in the file to match 4. Update any imports referencing the old class name 5. Update the robot's main Constants file:    <pre><code>// In Constants.java\npublic static final TunerConstants tunerConstants = new TunerConstants2024();\n// or if using different configurations for simulation:\npublic static final TunerConstants tunerConstants =\n    Constants.currentMode == Mode.SIM ?\n        new TunerConstantsSim() :\n        new TunerConstants2024();\n</code></pre>    This static field is used throughout the codebase to access swerve configurations.</p> <ol> <li>Keep both files - old constants serve as a reference and backup</li> </ol>"},{"location":"quickstart/#13-module-configuration","title":"1.3 Module Configuration","text":"<p>The swerve drive configuration is generated using Phoenix Tuner X's Swerve Generator tool:</p> <ol> <li>Launch Phoenix Tuner X and connect to the robot</li> <li>Open the Swerve Generator tool</li> <li> <p>Configure module hardware in Phoenix Tuner X:</p> <ul> <li>Select your motor type:<ul> <li>Kraken X60</li> <li>Falcon 500</li> </ul> </li> <li>Set gear ratios for drive and steer (based on your swerve module type)</li> <li>Input wheel radius</li> <li>Select encoder type:<ul> <li>CANcoder</li> <li>CANcoder 2.0</li> </ul> </li> </ul> </li> <li> <p>Set CAN IDs for each module:</p> <ul> <li>Drive Motor</li> <li>Turn Motor</li> <li>CANcoder</li> <li>Ensure IDs match physical hardware</li> </ul> </li> <li> <p>Zero all CANcoders:</p> <ul> <li>Point all wheels toward the center of the robot:<ul> <li>Bevel gears (black side) should face inward on all modules</li> <li>If available, use the module's zeroing holes with a 3/16\" bar</li> <li>If no zeroing holes, align wheels visually toward robot center</li> </ul> </li> <li>Double check all wheels are properly aligned</li> <li>Use Tuner X to record offsets</li> <li>Verify offsets are correct by powering off/on and checking wheel alignment</li> </ul> </li> <li> <p>Copying Generated Constants:</p> <ul> <li>The generator creates a complete constants file with all swerve configurations</li> <li>In your project, locate the <code>GeneratedConstants</code> inner class within your new <code>TunerConstants2024.java</code></li> <li>DO NOT replace the entire <code>TunerConstants2024.java</code> file</li> <li>Only copy the constant values from the generator output into your existing <code>GeneratedConstants</code> class</li> <li>This includes:<ul> <li>Module offsets</li> <li>Gear ratios</li> <li>PID gains</li> <li>Basic configurations</li> <li>Motor and encoder IDs</li> </ul> </li> <li>IMPORTANT: Delete or do not copy the <code>createSwerveDrive()</code> method<ul> <li>This method is not used in our implementation</li> <li>We handle swerve drive creation differently</li> </ul> </li> <li>Optional: Replace hardcoded CAN IDs with Constants references   <pre><code>// Replace generated values like:\npublic static final int kFrontLeftDriveMotorId = 1;\n\n// With references to Constants:\npublic static final int kFrontLeftDriveMotorId = Constants.CanId.FRONT_LEFT_DRIVE_MTR_CAN_ID;\n</code></pre>   This makes ID management more centralized and maintainable</li> <li>Leave all custom configurations in <code>CustomConstants</code> unchanged<ul> <li>These values (like translation PID, rotation PID, constraints) will be tuned later</li> <li>Do not overwrite them with generated values</li> </ul> </li> <li>The <code>TunerConstants2024.java</code> file implements <code>TunerConstants.java</code> and should maintain its structure</li> </ul> </li> </ol>"},{"location":"quickstart/#14-drive-system-testing","title":"1.4 Drive System Testing","text":"<p>After configuring modules and before PID tuning, verify basic functionality:</p> <ol> <li> <p>Initial Movement Check:</p> <ul> <li>Deploy code with default PID values:   <pre><code>// Default steer (turn) gains\nprivate static final Slot0Configs steerGains = new Slot0Configs()\n    .withKP(100)\n    .withKI(0)\n    .withKD(0.5)\n    .withKS(0.2)\n    .withKV(1.59)\n    .withKA(0)\n    .withStaticFeedforwardSign(StaticFeedforwardSignValue.UseClosedLoopSign);\n\n// Default drive gains\nprivate static final Slot0Configs driveGains = new Slot0Configs()\n    .withKP(0.1)\n    .withKI(0)\n    .withKD(0)\n    .withKS(0)\n    .withKV(0.124);\n</code></pre></li> <li>Lower robot onto ground</li> <li>Very slowly test each movement:<ul> <li>Forward/Backward</li> <li>Left/Right strafe</li> <li>Rotation</li> <li>Note: Movement may not be perfect yet as we use 254's Swerve Trajectory Setpoint Generator, which requires tuned PathPlanner constraints (we'll configure these in a later step)</li> </ul> </li> <li>Watch for:<ul> <li>All wheels spinning correct directions</li> <li>No grinding or unusual noises</li> <li>Basic responsiveness to commands</li> </ul> </li> </ul> </li> <li> <p>Module Behavior Verification:</p> <ul> <li>Watch each module individually</li> <li>Verify wheels point in expected directions</li> <li>Make sure drive motors move in sync</li> <li>Check for any modules \"fighting\" each other</li> </ul> </li> </ol>"},{"location":"quickstart/#15-drive-characterization","title":"1.5 Drive Characterization","text":"<p>Now we'll determine the feed-forward values:</p> <ol> <li> <p>Setup:</p> <ul> <li>Place robot in an open space</li> <li>Connect to robot via Driver Station</li> <li>Open AdvantageScope</li> </ul> </li> <li> <p>Run Characterization:    Select the \"Drive Simple FF Characterization\" auto routine.    Enable autonomous    Disable after 10-15s</p> <ul> <li>Command will gradually increase voltage</li> <li>Watch modules for smooth acceleration</li> <li>Let run until reaching full speed</li> <li>Values will print to Driver Station console</li> </ul> </li> <li> <p>Record Values:</p> <ul> <li>Look for kS and kV output in console</li> <li>Record both values for next step</li> <li>Run 2-3 times to verify consistency</li> </ul> </li> </ol>"},{"location":"quickstart/#16-drive-motor-tuning","title":"1.6 Drive Motor Tuning","text":"<p>Update PID and FF values based on characterization:</p> <ol> <li> <p>Initial Feed Forward:    <pre><code>// In GeneratedConstants:\npublic static final Slot0Configs driveGains = new Slot0Configs()\n    .withKS(/* value from characterization */)\n    .withKV(/* value from characterization */)\n    .withKA(0.01);  // Start small\n</code></pre></p> </li> <li> <p>Base PID Values:    <pre><code>public static final Slot0Configs driveGains = driveGains\n    .withKP(0.05)  // Start conservative\n    .withKI(0.0)   // Usually not needed\n    .withKD(0.0);  // Add only if needed\n</code></pre></p> </li> <li> <p>Testing Process:</p> <ul> <li>Deploy code</li> <li>Start with very slow movements</li> <li>Test forward/backward/strafe</li> <li>Plot values for</li> <li>/RealOutputs/SwerveStates/Measured</li> <li>/RealOutputs/SwerveStates/SetpointsOptimized</li> <li>Try to match the Measured value as close to Optimized as possible.</li> <li>Transitions won't be instant, but ensure that we don't over/under shoot</li> <li>Watch for:<ul> <li>Smooth acceleration</li> <li>No oscillation</li> <li>Wheels staying in sync</li> </ul> </li> </ul> </li> <li> <p>PID Tuning Steps:    a. If response is sluggish:</p> <ul> <li>Increase kP by 0.02</li> <li>Test movement</li> <li>Repeat until responsive</li> </ul> </li> </ol> <p>b. If modules oscillate:     - Reduce kP by 25%     - Add small kD (start 0.001)     - Test movement</p> <p>c. If wheels fight each other:     - Verify module offsets     - Check wheel direction conventions     - Reduce kP slightly</p> <ol> <li> <p>Velocity Tuning:</p> <ul> <li>Test at 25% speed:<ul> <li>Adjust kP until responsive</li> <li>Add kD if oscillating</li> </ul> </li> <li>Test at 50% speed:<ul> <li>Verify stability</li> <li>Adjust if needed</li> </ul> </li> <li>Test at full speed:<ul> <li>Final verification</li> <li>Fine-tune as needed</li> </ul> </li> </ul> </li> <li> <p>Final Testing:</p> <ul> <li>Run full-speed maneuvers</li> <li>Check quick direction changes</li> <li>Verify smooth acceleration</li> <li>Test rotation stability</li> <li>Look for any wheel slip</li> </ul> </li> </ol> <p>Your final drive gains might look like: <pre><code>public static final Slot0Configs driveGains = new Slot0Configs()\n    .withKP(0.09)\n    .withKI(0.0)\n    .withKD(0.001)\n    .withKS(0.19437)\n    .withKV(0.75843)\n    .withKA(0.01);\n</code></pre></p>"},{"location":"quickstart/#17-measuring-maximum-speed","title":"1.7 Measuring Maximum Speed","text":"<p>After tuning the drive motors, you'll need to measure the robot's actual maximum speed:</p> <ol> <li> <p>Safety First:</p> <ul> <li>Place the robot securely on blocks</li> <li>Ensure all wheels are free to spin</li> <li>Clear the area around the robot</li> <li>Have emergency stop ready</li> </ul> </li> <li> <p>Using Phoenix Tuner X:</p> <ul> <li>Connect to robot</li> <li>Open \"Plot\" view</li> <li>Select drive motors</li> <li>Use \"Control\" tab</li> <li>Set to \"Voltage Control\"</li> <li>Command 12V to drive motors</li> </ul> </li> <li> <p>Measuring Speed:</p> <ul> <li>Let motors reach full speed</li> <li>Record velocity from plot</li> <li>Take measurements from all modules</li> <li>Average the results</li> <li>Convert to your preferred units (meters/second)</li> </ul> </li> <li> <p>Updating Constants:</p> <ul> <li>Open your TunerConstants file</li> <li>Update the speed value: <pre><code>public static final LinearVelocity kSpeedAt12Volts = MetersPerSecond.of(5.02);\n</code></pre></li> <li>This value is used for:<ul> <li>Path planning</li> <li>Autonomous routines</li> <li>Speed limiting</li> <li>Controller scaling</li> </ul> </li> </ul> </li> <li> <p>Verification:</p> <ul> <li>Deploy updated code</li> <li>Test at various speed percentages</li> <li>Verify autonomous paths work correctly</li> <li>Check that speed limits are respected</li> </ul> </li> </ol>"},{"location":"quickstart/#18-slip-current-measurement","title":"1.8 Slip Current Measurement","text":"<p>After setting maximum speed, we need to determine the current limit that prevents wheel slip:</p> <ol> <li> <p>Setup:</p> <ul> <li>Position robot against a solid wall</li> <li>Open AdvantageScope</li> <li>Create plots for:<ul> <li>Drive motor current (/Drive/Module.../DriveCurrentAmps)</li> <li>Drive velocity (/Drive/Module.../DriveVelocityRadPerSec)</li> </ul> </li> </ul> </li> <li> <p>Measurement Process:</p> <ul> <li>Gradually increase forward throttle</li> <li>Watch velocity plot carefully</li> <li>When velocity suddenly increases (wheel slip), note the current</li> <li>This is your slip current threshold</li> </ul> </li> <li> <p>Updating Constants:</p> <ul> <li>Open your TunerConstants file</li> <li>Set kSlipCurrent to the measured value: <pre><code>public static final double kSlipCurrent = 40.0; // Amperes - adjust to your measured value\n</code></pre></li> <li>This prevents wheel slip during high-torque maneuvers</li> </ul> </li> <li> <p>Verification:</p> <ul> <li>Deploy updated code</li> <li>Test aggressive movements</li> <li>Verify wheels maintain traction</li> <li>Check performance on different surfaces</li> </ul> </li> </ol>"},{"location":"quickstart/#19-robot-mass-configuration","title":"1.9 Robot Mass Configuration","text":"<p>After setting up slip current limits, configure the robot's mass for PathPlanner:</p> <ol> <li> <p>Measure Robot Mass:</p> <ul> <li>Weigh the complete robot</li> <li>Include all components:<ul> <li>Battery</li> <li>Bumpers</li> <li>Game pieces (if carrying during auto)</li> </ul> </li> <li>Convert to kilograms</li> </ul> </li> <li> <p>Update Configuration:</p> <ul> <li>In your TunerConstants file, update the PathPlanner config: <pre><code>public static final double ROBOT_MASS_KG = 34; // Update with your measured mass\n</code></pre></li> </ul> </li> </ol>"},{"location":"quickstart/#110-robot-moment-of-inertia-measurement","title":"1.10 Robot Moment of Inertia Measurement","text":"<p>After configuring robot mass, measure the robot's rotational inertia (MOI) for better path following:</p> <ol> <li> <p>Code Preparation:</p> <ul> <li>Locate Module.java in your project</li> <li>Find the runCharacterization method (around line 89)</li> <li>Replace the existing method with: <pre><code>public void runCharacterization(double output) {\n    io.setDriveOpenLoop(output);\n    io.setTurnPosition(new Rotation2d(constants.LocationX, constants.LocationY).plus(Rotation2d.kCCW_Pi_2));\n}\n</code></pre></li> <li>Deploy the updated code to the robot</li> </ul> </li> <li> <p>Setup:</p> <ul> <li>Clear a large, flat area</li> <li>Place robot on smooth surface</li> <li>Connect to robot via Driver Station</li> <li>Open AdvantageScope for data logging</li> </ul> </li> <li> <p>Data Collection:</p> <ul> <li>Through dashboard autos, run each SysId routine:<ul> <li>Drive SysId (Quasistatic Forward)</li> <li>Drive SysId (Quasistatic Reverse)</li> <li>Drive SysId (Dynamic Forward)</li> <li>Drive SysId (Dynamic Reverse)</li> </ul> </li> <li>Let each routine run for atleast 15s</li> <li>Save logs after each run</li> </ul> </li> <li> <p>Data Export:</p> <ul> <li>Remove USB drive from robot</li> <li>Connect to computer</li> <li>Open AdvantageScope (v3.0.2 or later)</li> <li>Load the log file</li> <li>Go to \"File\" &gt; \"Export Data...\"</li> <li>Configure export settings:<ul> <li>Format: \"WPILOG\"</li> <li>Timestamps: \"AdvantageKit Cycles\"</li> <li>Select necessary fields for SysId</li> </ul> </li> <li>Save the converted log file</li> </ul> </li> <li> <p>SysId Analysis:</p> <ul> <li>Launch SysID</li> <li>Load the exported log file</li> <li>Record these values:<ul> <li>kA_angular (V/(rad/s\u00b2))</li> <li>kA_linear (V/(m/s\u00b2))</li> </ul> </li> </ul> </li> <li> <p>Calculate MOI:     Use this formula:     <pre><code>MOI = mass * (trackwidth/2) * (kA_angular/kA_linear)\n</code></pre>     Where:</p> <ul> <li>mass = robot mass in kg</li> <li>trackwidth = largest distance between wheel centers</li> <li>kA_angular = angular acceleration feedforward</li> <li>kA_linear = linear acceleration feedforward</li> </ul> </li> <li> <p>Update Configuration:</p> <ul> <li>In your TunerConstants file, update the MOI constant: <pre><code>public static final double ROBOT_MOI = 4.24; // Update with calculated value\n</code></pre> This value represents the robot's resistance to rotational acceleration</li> </ul> </li> </ol>"},{"location":"quickstart/#111-wheel-coefficient-of-friction-measurement","title":"1.11 Wheel Coefficient of Friction Measurement","text":"<p>After configuring mass and MOI, measure the wheel coefficient of friction for accurate path following:</p> <ol> <li>Locate the wheel COF on the manufacturer website, some common examples have been provided here:</li> <li>Most Colson wheels: 1.0</li> <li>BRAND NEW Billet Wheel, 4\"OD x 1.5\"W (MK4/4i/4n): 1.1 (THIS VALUE ONLY LASTS FOR 1-1.5 EVENTS WORTH OF USE)</li> <li>Update Configuration:<ul> <li>In your TunerConstants file, update the COF constant: <pre><code>public static final double WHEEL_COF = 1.1;  // Update with measured value\n</code></pre> This value helps PathPlanner calculate maximum achievable accelerations</li> </ul> </li> </ol>"},{"location":"quickstart/#112-turn-motor-tuning","title":"1.12 Turn Motor Tuning","text":"<p>The turn (steering) motors require different tuning approaches than drive motors:</p> <ol> <li> <p>Initial Setup:</p> <ul> <li>Ensure wheels can rotate freely</li> <li>Start with conservative values: <pre><code>public static final Slot0Configs steerGains = new Slot0Configs()\n    .withKP(40)\n    .withKI(0)\n    .withKD(0.1)\n    .withKS(0.12)\n    .withKV(0.102);\n</code></pre></li> </ul> </li> <li> <p>Position Control Testing:</p> <ul> <li>Deploy code with initial values</li> <li>Use driver station to command 90-degree turns</li> <li>Watch for:<ul> <li>Quick response without overshooting</li> <li>No oscillation at target position</li> <li>Smooth acceleration and deceleration</li> <li>Ability to hold position when pushed</li> </ul> </li> </ul> </li> <li> <p>PID Tuning Process:    a. Start with Position Control:</p> <ul> <li>Increase kP until wheels respond quickly</li> <li>If oscillating, reduce kP by 25%</li> <li>Add kD to dampen oscillations (start with kD = kP * 0.01)</li> <li>Adjust until wheels snap to position without overshooting</li> </ul> </li> </ol> <p>b. Add Feed Forward:     - Start with small kS (0.1-0.2)     - Increase if modules struggle to overcome friction     - Add kV based on max velocity requirements     - Keep kA at 0 unless needed for high acceleration</p> <ol> <li> <p>Common Issues:</p> <ul> <li>Oscillation: Reduce kP or increase kD</li> <li>Slow response: Increase kP</li> <li>Position drift: Increase kS slightly</li> <li>Overshooting: Increase kD or reduce kP</li> <li>Grinding noise: Check mechanical alignment and reduce gains</li> </ul> </li> <li> <p>Final Verification:</p> <ul> <li>Test rapid direction changes</li> <li>Verify holding position under load</li> <li>Check for smooth motion at various speeds</li> <li>Ensure all modules perform consistently</li> </ul> </li> </ol> <p>Your final turn gains might look like: <pre><code>public static final Slot0Configs steerGains = new Slot0Configs()\n    .withKP(55)\n    .withKI(0)\n    .withKD(0.2)\n    .withKS(0.12)\n    .withKV(0.102)\n    .withKA(0)\n    .withStaticFeedforwardSign(StaticFeedforwardSignValue.UseClosedLoopSign);\n</code></pre></p>"},{"location":"quickstart/#113-pathplanner-pid-tuning","title":"1.13 PathPlanner PID Tuning","text":"<p>The final step in swerve drive configuration is tuning the PathPlanner translation and rotation PIDs:</p> <ol> <li> <p>Initial Values:    These PIDs are defined in your TunerConstants file:    <pre><code>public static final PIDConstants translationPid = new PIDConstants(2.4, 0, 0.015);\npublic static final PIDConstants rotationPid = new PIDConstants(7.8, 0, 0.015);\n</code></pre></p> </li> <li> <p>Tuning Process:</p> <ul> <li>Open PathPlanner Desktop application</li> <li>Select the Telemetry tab</li> <li>Follow this sequence:<ol> <li>Run \"PP_StraightTest\"</li> <li>Adjust translationPid until actual path matches commanded path</li> <li>Focus on matching the translation slopes as closely as possible</li> <li>Run \"PP_RotationTest\"</li> <li>Tune rotationPid until rotation behavior is smooth and accurate</li> <li>Run \"PP_HoloTest\"</li> <li>Final verification of both PIDs working together</li> <li>Make minor adjustments if needed</li> </ol> </li> </ul> </li> <li> <p>Tips:</p> <ul> <li>Start with P term only</li> <li>Add D term to reduce oscillation</li> <li>I term usually not needed</li> <li>Test multiple times for consistency</li> <li>Save values after successful tuning</li> </ul> </li> </ol>"},{"location":"quickstart/#114-final-verification-testing","title":"1.14 Final Verification Testing","text":"<p>Before considering the swerve drive fully configured, perform these comprehensive tests:</p> <ol> <li> <p>Teleoperated Testing:</p> <ul> <li>Drive the robot in all directions:<ul> <li>Forward/backward at varying speeds</li> <li>Left/right strafing</li> <li>Diagonal movements</li> <li>Rotation while moving (both directions)</li> </ul> </li> <li>Check for:<ul> <li>Smooth acceleration/deceleration</li> <li>No unexpected jerking or hesitation</li> <li>Accurate response to joystick inputs</li> <li>Consistent behavior at all speeds</li> <li>No wheel scrubbing during rotation</li> <li>Proper tracking during diagonal movement</li> </ul> </li> </ul> </li> <li> <p>Autonomous Path Testing:</p> <ul> <li>Run several test paths:<ul> <li>Straight lines</li> <li>S-curves</li> <li>Figure-8 patterns</li> <li>Complex multi-part paths</li> </ul> </li> <li>Verify:<ul> <li>Robot follows commanded path closely</li> <li>No significant corner cutting</li> <li>Smooth transitions between path segments</li> <li>Consistent speed throughout paths</li> <li>Accurate final positioning</li> <li>Repeatable results across multiple runs</li> </ul> </li> </ul> </li> <li> <p>Edge Case Testing:</p> <ul> <li>Quick direction changes</li> <li>Full-speed emergency stops</li> <li>Operation near physical obstacles</li> <li>Movement on different surface materials</li> <li>Performance with varying battery voltage</li> <li>Behavior under maximum load conditions</li> </ul> </li> </ol> <p>Note: While the robot should now follow paths accurately, some remaining inaccuracies are normal and will be corrected later using vision-based localization systems.</p>"},{"location":"quickstart/#2-vision-coprocessor-setup","title":"2. Vision Coprocessor Setup","text":""},{"location":"quickstart/#21-initial-hardware-setup","title":"2.1 Initial Hardware Setup","text":"<ol> <li> <p>Coprocessor Preparation:</p> <ul> <li>Download latest Orange PI 5 PhotonVision image</li> <li>Flash image to microSD card</li> <li>Insert microSD into Orange PI 5</li> </ul> </li> <li> <p>Camera Naming:</p> <ul> <li>Download ArducamUVCSerialNumber_Official.zip</li> <li>Extract the program</li> <li>For each Arducam OV9281 camera:<ol> <li>Connect camera to laptop via USB</li> <li>Open ArducamUVCSerialNumber program</li> <li>In \"Device name\" field, enter camera position:<ul> <li>Format: <code>POSITION_AprilTag</code></li> <li>Examples: <code>FL_AprilTag</code>, <code>FM_AprilTag</code>, <code>FR_AprilTag</code></li> </ul> </li> <li>Click \"Write\"</li> <li>Open Device Manager</li> <li>Uninstall the camera</li> <li>Reconnect the camera</li> <li>Verify new name appears</li> <li>Disconnect from laptop</li> <li>Connect to Orange PI 5</li> </ol> </li> <li>Repeat for all cameras</li> </ul> </li> </ol>"},{"location":"quickstart/#22-photonvision-configuration","title":"2.2 PhotonVision Configuration","text":"<ol> <li> <p>Pipeline Setup:</p> <ul> <li>Open PhotonVision web interface</li> <li>For each camera:<ol> <li>Select camera in UI</li> <li>Create new pipeline named \"AprilTag\"</li> <li>Set pipeline type to \"AprilTag\"</li> <li>Configure processing:<ul> <li>Decimate: 2</li> <li>Blur: 1</li> <li>Auto White Balance: ON</li> </ul> </li> <li>Set camera settings:<ul> <li>Resolution: 1280x720</li> <li>FPS: 100 (or similar)</li> <li>Stream Resolution: Lowest available</li> </ul> </li> <li>Navigate to Cameras tab</li> <li>Select camera</li> <li>Set Model as \"OV9281\"</li> </ol> </li> </ul> </li> <li> <p>Camera Calibration:</p> <ul> <li>For each camera:<ol> <li>Select calibration settings:<ul> <li>Tag Family: 5x5</li> <li>Resolution: 720p</li> <li>Pattern Spacing: 3.15 inches</li> <li>Marker Size: 2.36 inches</li> <li>Board: 12x8</li> </ul> </li> <li>Take multiple calibration snapshots:<ul> <li>Vary angles and distances</li> <li>Include corner views</li> <li>Mix close and far positions</li> </ul> </li> <li>Run calibration</li> <li>Verify mean error &lt; 1.0 pixels</li> <li>If error too high:<ul> <li>Delete poor quality snapshots</li> <li>Add more varied angles</li> <li>Recalibrate</li> </ul> </li> </ol> </li> </ul> </li> <li> <p>Final Configuration:</p> <ul> <li>For each pipeline:<ol> <li>Enable 3D mode</li> <li>Enable multi-tag detection</li> <li>Save settings</li> </ol> </li> </ul> </li> <li> <p>Field Tuning:</p> <ul> <li>At competition field:<ul> <li>Adjust exposure</li> <li>Tune brightness</li> <li>Set appropriate gain</li> <li>Test detection reliability</li> <li>Save field-specific settings</li> </ul> </li> </ul> </li> </ol>"},{"location":"quickstart/#3-apriltag-vision-configuration","title":"3. AprilTag Vision Configuration","text":""},{"location":"quickstart/#21-camera-offset-measurement","title":"2.1 Camera Offset Measurement","text":"<p>Accurate camera position measurements are critical for AprilTag vision:</p> <ol> <li> <p>Physical Measurements:</p> <ul> <li>Use calipers or precise measuring tools</li> <li>Measure from robot center (origin) to camera lens center</li> <li>Record three distances for each camera:<ul> <li>Forward distance (X): positive towards robot front</li> <li>Left distance (Y): positive towards robot left</li> <li>Up distance (Z): positive towards robot top</li> </ul> </li> <li>Measure camera angles:<ul> <li>Pitch: downward tilt (usually negative)</li> <li>Yaw: left/right rotation</li> </ul> </li> </ul> </li> <li> <p>Update Constants:     <pre><code>private static final Transform3d[] CAMERA_OFFSETS = new Transform3d[] {\n    // Front Left Camera\n    new Transform3d(\n        new Translation3d(0.245, 0.21, 0.17),  // X, Y, Z in meters\n        new Rotation3d(0, Math.toRadians(-35), Math.toRadians(45))),  // Roll, Pitch, Yaw\n\n    // Front Middle Camera\n    new Transform3d(\n        new Translation3d(0.275, 0.0, 0.189),\n        new Rotation3d(0, Math.toRadians(-35), Math.toRadians(0)))\n};\n</code></pre></p> </li> <li> <p>Camera Configuration:     <pre><code>// Add configuration for each physical camera\nprivate static final CameraConfig[] CAMERA_CONFIGS = new CameraConfig[] {\n    new CameraConfig(\"FL_AprilTag\", CAMERA_OFFSETS[0], new SimCameraProperties()),\n    new CameraConfig(\"FM_AprilTag\", CAMERA_OFFSETS[1], new SimCameraProperties())\n};\n</code></pre></p> </li> <li> <p>IO Configuration:     <pre><code>// In RobotContainer.java constructor:\naprilTagSubsystem =\n        new AprilTagSubsystem(\n            swerveDriveSubsystem::addVisionMeasurement,\n            new AprilTagIOPhotonVision(AprilTagConstants.CAMERA_CONFIGS[0]),\n            new AprilTagIOPhotonVision(AprilTagConstants.CAMERA_CONFIGS[1]));\n</code></pre></p> </li> <li> <p>Replay Support:     <pre><code>// For replay mode, match array size to physical cameras\naprilTagSubsystem =\n        new AprilTagSubsystem(\n            swerveDriveSubsystem::addVisionMeasurement,\n            new AprilTagIO() {},\n            new AprilTagIO() {});\n</code></pre></p> </li> </ol>"},{"location":"quickstart/#22-camera-verification","title":"2.2 Camera Verification","text":"<p>After configuring camera offsets:</p> <ol> <li> <p>Physical Checks:</p> <ul> <li>Verify camera mounts are secure</li> <li>Check USB connections</li> <li>Confirm cameras are powered</li> <li>LED indicators should be on</li> </ul> </li> <li> <p>Network Verification:</p> <ul> <li>Open PhotonVision dashboard</li> <li>Confirm all cameras are connected</li> <li>Check video feeds are active</li> <li>Verify camera names match configs</li> </ul> </li> <li> <p>Basic Testing:</p> <ul> <li>Hold AprilTag in camera view</li> <li>Confirm detection in dashboard</li> <li>Check pose estimation quality</li> <li>Verify reasonable distance estimates</li> </ul> </li> <li> <p>Optional Camera Tuning:</p> <ul> <li> <p>Camera Trust Factors:     <pre><code>// Standard deviation multipliers for each camera\n// (Adjust to trust some cameras more than others)\n// SHOULD NEVER BE LESS THAN 1.0, NUMBERS GREATER THAN 1 = TRUST LESS\npublic static double[] CAMERA_STD_DEV_FACTORS = new double[] {1.0, 1.0};\n</code></pre></p> <ul> <li>Higher values = trust that camera less</li> <li>Example: <code>{1.0, 1.5}</code> trusts first camera more than second</li> <li>Never use values less than 1.0</li> <li>Useful when some cameras are more reliable than others</li> </ul> </li> <li> <p>Ambiguity Filtering:     <pre><code>public static double MAX_AMBIGUITY = 0.3;\n</code></pre></p> <ul> <li>Filters out less confident tag detections</li> <li>Lower values = stricter filtering</li> <li>Range 0.0 to 1.0</li> <li>Start with 0.3 and adjust based on false positive rate</li> </ul> </li> </ul> </li> <li> <p>Common Issues:</p> <ul> <li>Camera disconnections: Check USB connections</li> <li>Poor detection: Adjust exposure/brightness</li> <li>Incorrect poses: Double-check offset measurements</li> <li>Network lag: Monitor bandwidth usage</li> </ul> </li> </ol>"},{"location":"quickstart/#3-object-detection-configuration","title":"3. Object Detection Configuration","text":""},{"location":"quickstart/#31-initial-hardware-setup","title":"3.1 Initial Hardware Setup","text":"<ol> <li>Camera Naming:<ul> <li>Download ArducamUVCSerialNumber_Official.zip</li> <li>Extract the program</li> <li>For each Arducam OV9782 camera:<ol> <li>Connect camera to laptop via USB</li> <li>Open ArducamUVCSerialNumber program</li> <li>In \"Device name\" field, enter camera position:<ul> <li>Format: <code>POSITION_Object</code></li> <li>Examples: <code>FL_Object</code>, <code>FM_Object</code>, <code>FR_Object</code></li> </ul> </li> <li>Click \"Write\"</li> <li>Open Device Manager</li> <li>Uninstall the camera</li> <li>Reconnect the camera</li> <li>Verify new name appears</li> <li>Disconnect from laptop</li> <li>Connect to Orange PI 5</li> </ol> </li> <li>Repeat for all cameras</li> </ul> </li> </ol>"},{"location":"quickstart/#32-photonvision-configuration","title":"3.2 PhotonVision Configuration","text":"<ol> <li> <p>Pipeline Setup:</p> <ul> <li>Open PhotonVision web interface</li> <li>For each camera:<ol> <li>Select camera in UI</li> <li>Create new pipeline named \"ObjectDetection\"</li> <li>Set pipeline type to \"ObjectDetection\"</li> <li>Configure processing:<ul> <li>Auto White Balance: ON</li> </ul> </li> <li>Set camera settings:<ul> <li>Resolution: 1280x720</li> <li>FPS: 30 (or similar)</li> <li>Stream Resolution: Lowest available</li> </ul> </li> <li>Navigate to Cameras tab</li> <li>Select camera</li> <li>Set Model as \"OV9782\"</li> </ol> </li> </ul> </li> <li> <p>Camera Calibration:</p> <ul> <li>For each camera:<ol> <li>Select calibration settings:<ul> <li>Tag Family: 5x5</li> <li>Resolution: 720p</li> <li>Pattern Spacing: 3.15 inches</li> <li>Marker Size: 2.36 inches</li> <li>Board: 12x8</li> </ul> </li> <li>Take multiple calibration snapshots:<ul> <li>Vary angles and distances</li> <li>Include corner views</li> <li>Mix close and far positions</li> </ul> </li> <li>Run calibration</li> <li>Verify mean error &lt; 1.0 pixels</li> <li>If error too high:<ul> <li>Delete poor quality snapshots</li> <li>Add more varied angles</li> <li>Recalibrate</li> </ul> </li> </ol> </li> </ul> </li> <li> <p>Field Tuning:</p> <ul> <li>At competition field:<ul> <li>Adjust exposure</li> <li>Tune brightness</li> <li>Set appropriate gain</li> <li>Test detection reliability</li> <li>Save field-specific settings</li> </ul> </li> </ul> </li> </ol>"},{"location":"quickstart/#33-camera-offset-measurement","title":"3.3 Camera Offset Measurement","text":"<p>Accurate camera position measurements are critical for object detection:</p> <ol> <li> <p>Physical Measurements:</p> <ul> <li>Use calipers or precise measuring tools</li> <li>Measure from robot center (origin) to camera lens center</li> <li>Record three distances for each camera:<ul> <li>Forward distance (X): positive towards robot front</li> <li>Left distance (Y): positive towards robot left</li> <li>Up distance (Z): positive towards robot top</li> </ul> </li> <li>Measure camera angles:<ul> <li>Pitch: downward tilt (usually negative)</li> <li>Yaw: left/right rotation</li> </ul> </li> </ul> </li> <li> <p>Update Constants:     <pre><code>private static final Transform3d[] CAMERA_OFFSETS =\n  new Transform3d[] {\n    // Front Middle\n    new Transform3d(\n        new Translation3d(0.275, 0.0, 0.23),\n        new Rotation3d(0, Math.toRadians(0), Math.toRadians(0)))\n  };\n</code></pre></p> </li> <li> <p>Camera Configuration:     <code>java     // Add configuration for each physical camera     public static final CameraConfig[] CAMERA_CONFIGS = {     new CameraConfig(         \"FM_ObjectDetection\",         CAMERA_OFFSETS[0],         new SimCameraProperties())    };</code></p> </li> <li> <p>IO Configuration:     <pre><code>// In RobotContainer.java constructor:\nobjectDetectionSubsystem =\n        new ObjectDetectionSubsystem(\n            swerveDriveSubsystem::getPose,\n            new ObjectDetectionIOPhotonVision(ObjectDetectionConstants.CAMERA_CONFIGS[0]));\n</code></pre></p> </li> <li> <p>Replay Support:     <pre><code>// For replay mode, match array size to physical cameras\nobjectDetectionSubsystem =\n        new ObjectDetectionSubsystem(swerveDriveSubsystem::getPose, new ObjectDetectionIO() {});\n</code></pre></p> </li> </ol>"},{"location":"quickstart/#34-game-element-configuration","title":"3.4 Game Element Configuration","text":"<p>Before testing object detection, configure the game elements that need to be detected:</p> <ol> <li> <p>Define Game Elements:     <pre><code>// In GameElementConstants.java\n// All measurements in meters\npublic static final GameElement NOTE = new GameElement(\"Note\", 0.36, 0.36, 0.05);\n</code></pre></p> </li> <li> <p>Create Class ID Array:     <pre><code>// Game elements array indexed by class ID\n// IMPORTANT: Order must match neural network model's class IDs\npublic static final GameElement[] GAME_ELEMENTS = new GameElement[] {\n    NOTE      // Class ID 0\n};\n</code></pre></p> </li> <li> <p>Important Considerations:</p> <ul> <li>Array indices must match model's class IDs exactly</li> <li>Measurements must be in meters</li> <li>Dimensions are width, length, height</li> <li>Names should match what's shown in PhotonVision</li> </ul> </li> </ol>"},{"location":"quickstart/#35-camera-verification","title":"3.5 Camera Verification","text":"<p>After configuring cameras and game elements:</p> <ol> <li> <p>Physical Checks:</p> <ul> <li>Verify camera mounts are secure</li> <li>Check USB connections</li> <li>Confirm cameras are powered</li> <li>LED indicators should be on</li> </ul> </li> <li> <p>Network Verification:</p> <ul> <li>Open PhotonVision dashboard</li> <li>Confirm all cameras are connected</li> <li>Check video feeds are active</li> <li>Verify camera names match configs</li> </ul> </li> <li> <p>Basic Testing:</p> <ul> <li>Place game piece in camera view</li> <li>Confirm detection in dashboard</li> <li>Check pose estimation quality</li> <li>Verify reasonable distance estimates</li> </ul> </li> <li> <p>Filtering Configuration:</p> <ul> <li>Position Match Tolerance:     <pre><code>// Tolerance in meters for matching object positions\n// Default is usually fine, but can be adjusted if needed\npublic static final double POSITION_MATCH_TOLERANCE = 0.5;\n</code></pre><ul> <li>Larger values: More stable tracking during rotation</li> <li>Smaller values: More accurate position tracking</li> <li>Trade-off between stability and accuracy</li> <li>Start with default and adjust if objects appear unstable</li> </ul> </li> </ul> </li> <li> <p>Common Issues:</p> <ul> <li>Camera disconnections: Check USB connections</li> <li>Poor detection: Adjust exposure/brightness</li> <li>Incorrect poses: Double-check offset measurements</li> <li>Network lag: Monitor bandwidth usage</li> <li>Unstable tracking: Try increasing POSITION_MATCH_TOLERANCE</li> <li>Position jumps: Try decreasing POSITION_MATCH_TOLERANCE</li> </ul> </li> </ol> <p>Congratulations! Your project should now be fully configured and tuned for optimal performance.</p>"},{"location":"styleguide/","title":"Code Style Guide","text":""},{"location":"styleguide/#project-structure","title":"Project Structure","text":""},{"location":"styleguide/#base-package","title":"Base Package","text":"<pre><code>frc.alotobots/\n\u251c\u2500\u2500 Main.java                 # Entry point\n\u251c\u2500\u2500 Robot.java               # Robot lifecycle\n\u251c\u2500\u2500 RobotContainer.java      # Subsystem and command management\n\u251c\u2500\u2500 Constants.java           # Robot-wide constants\n\u2514\u2500\u2500 OI.java                  # Operator interface\n</code></pre>"},{"location":"styleguide/#subsystems-structure-library","title":"Subsystems Structure (Library)","text":"<pre><code>library.subsystems/\n\u251c\u2500\u2500 subsystem_name/\n\u2502   \u251c\u2500\u2500 commands/            # Commands specific to this subsystem\n\u2502   \u251c\u2500\u2500 constants/          # Subsystem-specific constants\n\u2502   \u251c\u2500\u2500 io/                # Hardware abstraction layer\n\u2502   \u2514\u2500\u2500 util/              # Utility classes for this subsystem\n</code></pre>"},{"location":"styleguide/#subsystems-structure-game-specific","title":"Subsystems Structure (Game Specific)","text":"<pre><code>game.subsystems/\n\u251c\u2500\u2500 subsystem_name/\n\u2502   \u251c\u2500\u2500 commands/            # Commands specific to this subsystem\n\u2502   \u251c\u2500\u2500 constants/          # Subsystem-specific constants\n\u2502   \u251c\u2500\u2500 io/                # Hardware abstraction layer\n\u2502   \u2514\u2500\u2500 util/              # Utility classes for this subsystem\n</code></pre> <p>All other commands that require multiple subsystems are placed in a subdirectory of game or library named <code>commands</code>.</p>"},{"location":"styleguide/#naming-conventions","title":"Naming Conventions","text":""},{"location":"styleguide/#files","title":"Files","text":"<ul> <li>Subsystems: <code>*Subsystem.java</code> (e.g., <code>SwerveDriveSubsystem.java</code>)</li> <li>Commands: <code>*.java</code> (e.g., <code>DefaultDrive.java</code>)</li> <li>Constants: <code>*Constants.java</code> (e.g., <code>SwerveDriveConstants.java</code>)</li> <li>IO Interfaces: <code>*IO.java</code> (e.g., <code>ModuleIO.java</code>)</li> <li>IO Implementations: <code>*IO{Implementation}.java</code> (e.g., <code>ModuleIOTalonFX.java</code>)</li> </ul>"},{"location":"styleguide/#variables","title":"Variables","text":"<ul> <li>Constants: <code>UPPER_SNAKE_CASE</code></li> <li>Instance variables: <code>camelCase</code></li> <li>Static variables: <code>camelCase</code></li> </ul>"},{"location":"styleguide/#code-organization","title":"Code Organization","text":""},{"location":"styleguide/#subsystem-pattern","title":"Subsystem Pattern","text":"<p>Each subsystem should follow this organization: <pre><code>public class ExampleSubsystem extends SubsystemBase {\n    // Hardware/IO variables\n    private final ExampleIO io;\n\n    // State variables\n    private final ExampleInputsAutoLogged inputs = new ExampleInputsAutoLogged();\n\n    // Constructor\n    public ExampleSubsystem(ExampleIO io) {\n        this.io = io;\n    }\n\n    // Periodic methods\n    @Override\n    public void periodic() { }\n\n    // Public methods\n\n    // Private helper methods\n}\n</code></pre></p>"},{"location":"styleguide/#command-pattern","title":"Command Pattern","text":"<p>Commands should follow this organization: <pre><code>public class ExampleCommand extends CommandBase {\n    // Subsystem dependencies\n    private final ExampleSubsystem subsystem;\n\n    // Command state\n\n    // Constructor\n    public ExampleCommand(ExampleSubsystem subsystem) {\n        this.subsystem = subsystem;\n        addRequirements(subsystem);\n    }\n\n    // Command lifecycle methods\n    @Override\n    public void initialize() { }\n\n    @Override\n    public void execute() { }\n\n    @Override\n    public void end(boolean interrupted) { }\n\n    @Override\n    public boolean isFinished() { }\n}\n</code></pre></p>"},{"location":"styleguide/#hardware-abstraction","title":"Hardware Abstraction","text":"<ul> <li>All hardware interactions must go through IO interfaces</li> <li>Real hardware implementations in <code>io</code> package</li> <li>Simulation implementations in same package with <code>Sim</code> suffix</li> <li>Use empty implementations for replay mode</li> </ul>"},{"location":"styleguide/#constants-organization","title":"Constants Organization","text":"<ul> <li>Robot-wide constants in <code>Constants.java</code></li> <li>Subsystem-specific constants in respective <code>constants</code> package</li> <li>Use inner classes to organize related constants</li> <li>All constants should be final</li> </ul>"},{"location":"styleguide/#testing-and-simulation","title":"Testing and Simulation","text":"<ul> <li>Simulation support implemented for critical subsystems only<ul> <li>Required for drive system</li> <li>Optional for other subsystems unless specifically needed</li> </ul> </li> <li>Characterization commands available for drive system tuning</li> <li>Log relevant data using AdvantageKit</li> <li>Simulation implementations should be maintained when provided by WPILib or vendor libraries</li> </ul>"},{"location":"styleguide/#documentation","title":"Documentation","text":"<ul> <li>JavaDoc required for all public methods</li> <li>Class-level documentation explaining purpose</li> <li>Constants must include units in documentation</li> <li>Command requirements and effects must be documented</li> </ul>"},{"location":"styleguide/#best-practices","title":"Best Practices","text":"<ol> <li>Use dependency injection for hardware IO</li> <li>Keep subsystems focused and single-purpose</li> <li>Commands should be small and composable</li> <li>Use AdvantageKit logging consistently</li> <li>Follow WPILib command-based paradigms</li> <li>Maintain simulation support for all features</li> <li>Use PhotonVision conventions for vision processing</li> <li>Implement both real and simulated hardware interfaces</li> </ol>"},{"location":"styleguide/#version-control","title":"Version Control","text":"<ul> <li>Feature branches for new development</li> <li>Pull requests required for merging</li> <li>Continuous Integration checks for style</li> <li>Version tags for competition code</li> <li>Automated builds for releases</li> </ul>"},{"location":"core/autonamedcommands/","title":"Auto Named Commands Utility","text":"<p>A utility class designed to register named commands with PathPlanner's autonomous functionality. This system allows commands to be referenced by name in PathPlanner autonomous routines.</p>"},{"location":"core/autonamedcommands/#purpose","title":"Purpose","text":"<p>The AutoNamedCommands utility serves as a central registration point for all commands that need to be accessible by name in PathPlanner paths. It maintains a static map of command names to their corresponding Command objects.</p>"},{"location":"core/autonamedcommands/#constructor","title":"Constructor","text":"<p>This is a utility class with no constructor - all members are static.</p>"},{"location":"core/autonamedcommands/#configuration-required","title":"Configuration Required","text":"<p>To use this utility:</p> <ol> <li> <p>Add commands to the <code>commands</code> HashMap using the pattern: <pre><code>put(\"COMMAND_NAME\", new YourCommand());\n</code></pre></p> </li> <li> <p>Call <code>AutoNamedCommands.setupNamedCommands()</code> during robot initialization to register all commands with PathPlanner.</p> </li> </ol>"},{"location":"core/autonamedcommands/#commands-using-this-utility","title":"Commands Using This Utility","text":"<p>Any command that needs to be referenced by name in a PathPlanner path must be registered through this utility.</p>"},{"location":"core/autonamedcommands/#javadoc-reference","title":"JavaDoc Reference","text":"<p>Complete documentation can be found here</p>"},{"location":"core/bindings/","title":"Button Bindings Overview","text":""},{"location":"core/bindings/#driver-controller-port-0","title":"Driver Controller (Port 0)","text":"<p>Xbox Controller mapping for primary robot control.</p>"},{"location":"core/bindings/#joysticks","title":"Joysticks","text":"<ul> <li>Left Stick<ul> <li>Y-Axis: Drive forward/backward</li> <li>X-Axis: Drive left/right</li> </ul> </li> <li>Right Stick<ul> <li>X-Axis: Robot rotation</li> </ul> </li> </ul>"},{"location":"core/bindings/#triggers","title":"Triggers","text":"<ul> <li>Left Trigger: Turtle (slow) mode</li> <li>Right Trigger: Turbo (fast) mode</li> </ul>"},{"location":"core/bindings/#buttons","title":"Buttons","text":"<ul> <li>A Button: Toggle drive facing best object</li> <li>B Button: Hold to pathfind to best object</li> </ul>"},{"location":"core/bindings/#controller-port-assignments","title":"Controller Port Assignments","text":"<ul> <li>Driver Controller: Port 0</li> </ul>"},{"location":"core/bindings/#configuration-notes","title":"Configuration Notes","text":"<ul> <li>Inputs use a deadband of 0.1</li> <li>All drive inputs are field-relative</li> <li>Speed modifiers affect all drive axes simultaneously</li> <li>Button bindings are configured in RobotContainer's configureLogicCommands()</li> <li>Raw controller access available through OI class methods</li> </ul>"},{"location":"core/bindings/#related-documentation","title":"Related Documentation","text":"<ul> <li>Operator Interface</li> <li>Controls Constants</li> </ul>"},{"location":"core/constants/","title":"Constants","text":"<p>The robot-wide constants class that defines core configuration values and runtime modes. This class serves as the central location for all robot-wide constants and device configurations.</p>"},{"location":"core/constants/#purpose","title":"Purpose","text":"<p>The Constants class provides: - Runtime mode configuration (REAL/SIM/REPLAY) - CAN device ID assignments - Global configuration values - Hardware device mappings</p>"},{"location":"core/constants/#configuration-required","title":"Configuration Required","text":"<ol> <li>Set simMode to the desired simulation mode (SIM/REPLAY) when not running on real hardware</li> <li>Configure CAN IDs for all devices to match physical hardware</li> <li>Update tuner constants for drive system configuration</li> </ol>"},{"location":"core/constants/#dependencies","title":"Dependencies","text":"<ul> <li>Robot mode affects initialization in RobotContainer</li> <li>CAN IDs must match physical hardware configuration</li> <li>Tuner constants must match drive system hardware</li> </ul>"},{"location":"core/constants/#javadoc-reference","title":"JavaDoc Reference","text":"<p>Complete documentation can be found here</p>"},{"location":"core/main/","title":"Main Class","text":"<p>The entry point class for the robot program. This class contains the main method that starts the robot code execution.</p>"},{"location":"core/main/#purpose","title":"Purpose","text":"<p>The Main class serves as the program entry point and: - Starts the robot code execution - Configures the robot base class - Prevents any premature initialization</p>"},{"location":"core/main/#configuration-required","title":"Configuration Required","text":"<p>No configuration is required. This class should not be modified except to change the robot class type in the startRobot call if necessary.</p>"},{"location":"core/main/#dependencies","title":"Dependencies","text":"<ul> <li>Robot - The main robot class that is started by Main</li> </ul>"},{"location":"core/main/#javadoc-reference","title":"JavaDoc Reference","text":"<p>Complete documentation can be found here</p>"},{"location":"core/oi/","title":"Operator Interface (OI)","text":"<p>The Operator Interface class manages all driver control inputs and button bindings for the robot. It provides a centralized location for configuring and accessing driver controls.</p>"},{"location":"core/oi/#purpose","title":"Purpose","text":"<p>The OI class handles: - Driver controller configuration - Joystick axis mapping - Button binding definitions - Speed control modifiers</p>"},{"location":"core/oi/#configuration-required","title":"Configuration Required","text":"<ol> <li>Controller port assignments (default port 0 for driver controller)</li> <li>Deadband value for joystick inputs</li> <li>Axis mapping for drive controls</li> <li>Button binding assignments</li> </ol>"},{"location":"core/oi/#dependencies","title":"Dependencies","text":"<ul> <li>WPILib CommandXboxController for input handling</li> <li>Command bindings referenced in RobotContainer</li> </ul>"},{"location":"core/oi/#javadoc-reference","title":"JavaDoc Reference","text":"<p>Complete documentation can be found here</p>"},{"location":"core/robot/","title":"Robot Class","text":"<p>The main robot class that handles the robot's lifecycle and operating modes. This class extends LoggedRobot to integrate with AdvantageKit logging framework and manages all robot operations.</p>"},{"location":"core/robot/#purpose","title":"Purpose","text":"<p>The Robot class serves as the main entry point for the robot code and handles: - Mode transitions (autonomous, teleop, test, disabled) - Command scheduling - AdvantageKit logging setup - High-priority periodic updates</p>"},{"location":"core/robot/#constructor-parameters","title":"Constructor Parameters","text":"<p>The Robot constructor initializes several key components: - Sets up AdvantageKit logging based on the current mode (REAL/SIM/REPLAY) - Records build metadata (Git info, build date, etc.) - Creates the RobotContainer instance</p>"},{"location":"core/robot/#requirements","title":"Requirements","text":""},{"location":"core/robot/#configuration","title":"Configuration","text":"<ol> <li>USB drive mounted at \"/U/logs\" for logging in REAL mode</li> <li>Properly configured Constants.currentMode</li> <li>Valid RobotContainer implementation</li> </ol>"},{"location":"core/robot/#dependencies","title":"Dependencies","text":"<ul> <li>RobotContainer</li> <li>Constants</li> <li>AdvantageKit logging framework</li> </ul>"},{"location":"core/robot/#javadoc-reference","title":"JavaDoc Reference","text":"<p>Complete documentation can be found here</p>"},{"location":"core/robotcontainer/","title":"RobotContainer Class","text":"<p>The central class that manages all subsystems and commands for the robot. It handles subsystem initialization, command configuration, and autonomous routine selection.</p>"},{"location":"core/robotcontainer/#purpose","title":"Purpose","text":"<p>RobotContainer serves as the main organizational structure for the robot's subsystems and commands. It: - Initializes all subsystems with appropriate IO implementations for real hardware, simulation, or replay modes - Configures subsystem default commands - Sets up command bindings - Manages autonomous routine selection - Provides system identification routines for tuning</p>"},{"location":"core/robotcontainer/#subsystems-managed","title":"Subsystems Managed","text":"<p>The RobotContainer manages all robot subsystems, handling their initialization, dependencies, and interactions. Each subsystem is initialized with the appropriate IO layer based on whether the robot is running in real hardware, simulation, or replay mode.</p>"},{"location":"core/robotcontainer/#configuration-required","title":"Configuration Required","text":"<ol> <li>Constants.currentMode must be set appropriately for target environment (REAL/SIM/REPLAY)</li> <li>PathPlanner autonomous routines must be properly configured</li> <li>Hardware devices must be configured with correct CAN IDs (see Constants)</li> <li>Camera configurations must be set in vision constants</li> </ol>"},{"location":"core/robotcontainer/#javadoc-reference","title":"JavaDoc Reference","text":"<p>Complete documentation can be found here</p>"},{"location":"javadoc/legal/jquery/","title":"Jquery","text":""},{"location":"javadoc/legal/jquery/#jquery-v371","title":"jQuery v3.7.1","text":""},{"location":"javadoc/legal/jquery/#jquery-license","title":"jQuery License","text":"<pre><code>jQuery v 3.7.1\nCopyright OpenJS Foundation and other contributors, https://openjsf.org/\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n</code></pre>"},{"location":"javadoc/legal/jqueryUI/","title":"jqueryUI","text":""},{"location":"javadoc/legal/jqueryUI/#jquery-ui-v1132","title":"jQuery UI v1.13.2","text":""},{"location":"javadoc/legal/jqueryUI/#jquery-ui-license","title":"jQuery UI License","text":"<pre><code>Copyright jQuery Foundation and other contributors, https://jquery.org/\n\nThis software consists of voluntary contributions made by many\nindividuals. For exact contribution history, see the revision history\navailable at https://github.com/jquery/jquery-ui\n\nThe following license applies to all parts of this software except as\ndocumented below:\n\n====\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n====\n\nCopyright and related rights for sample code are waived via CC0. Sample\ncode is defined as all source code contained within the demos directory.\n\nCC0: http://creativecommons.org/publicdomain/zero/1.0/\n\n====\n\nAll files located in the node_modules and external directories are\nexternally maintained libraries used by this software which have their\nown licenses; we recommend you read them, as their terms may differ from\nthe terms above.\n</code></pre>"},{"location":"library/commands/bling/noalliancewaiting/","title":"No Alliance Waiting Command","text":"<p>A command that displays a warning animation when no alliance color has been selected. The command automatically terminates once an alliance is selected in the Driver Station.</p>"},{"location":"library/commands/bling/noalliancewaiting/#required-subsystems","title":"Required Subsystems","text":"<ul> <li>Bling Subsystem</li> </ul>"},{"location":"library/commands/bling/noalliancewaiting/#constructor-parameters","title":"Constructor Parameters","text":"<p><pre><code>public NoAllianceWaiting(BlingSubsystem blingSubsystem)\n</code></pre> - <code>blingSubsystem</code>: The bling subsystem instance to control</p>"},{"location":"library/commands/bling/noalliancewaiting/#configuration-requirements","title":"Configuration Requirements","text":"<p>None - uses predefined NO_ALLIANCE_ANIMATION from BlingConstants</p>"},{"location":"library/commands/bling/noalliancewaiting/#reference-documentation","title":"Reference Documentation","text":"<p>No Alliance Waiting Command Javadoc</p>"},{"location":"library/commands/bling/settoalliancecolor/","title":"Set To Alliance Color Command","text":"<p>A command that sets the LED colors to match the current alliance color (red or blue) selected in the Driver Station. This provides a clear visual indicator of which alliance the robot is assigned to.</p>"},{"location":"library/commands/bling/settoalliancecolor/#required-subsystems","title":"Required Subsystems","text":"<ul> <li>Bling Subsystem</li> </ul>"},{"location":"library/commands/bling/settoalliancecolor/#constructor-parameters","title":"Constructor Parameters","text":"<p><pre><code>public SetToAllianceColor(BlingSubsystem blingSubsystem)\n</code></pre> - <code>blingSubsystem</code>: The bling subsystem instance to control</p>"},{"location":"library/commands/bling/settoalliancecolor/#configuration-requirements","title":"Configuration Requirements","text":"<p>None - uses predefined RED_ALLIANCE_COLOR and BLUE_ALLIANCE_COLOR from BlingConstants</p>"},{"location":"library/commands/bling/settoalliancecolor/#reference-documentation","title":"Reference Documentation","text":"<p>Set To Alliance Color Command Javadoc</p>"},{"location":"library/commands/swerve/characterization/","title":"Swerve Drive Characterization Commands","text":""},{"location":"library/commands/swerve/characterization/#overview","title":"Overview","text":"<p>The characterization commands provide system identification capabilities for the swerve drive subsystem. These commands enable precise measurement and calculation of critical system parameters.</p>"},{"location":"library/commands/swerve/characterization/#required-subsystems","title":"Required Subsystems","text":"<ul> <li>SwerveDriveSubsystem</li> </ul>"},{"location":"library/commands/swerve/characterization/#commands","title":"Commands","text":""},{"location":"library/commands/swerve/characterization/#wheelradiuscharacterization","title":"WheelRadiusCharacterization","text":"<p>Measures and calculates the effective wheel radius of the swerve modules.</p>"},{"location":"library/commands/swerve/characterization/#parameters","title":"Parameters","text":"<ul> <li><code>swerveDriveSubsystem</code>: The SwerveDrive subsystem instance to characterize</li> </ul>"},{"location":"library/commands/swerve/characterization/#output","title":"Output","text":"<p>Provides: - Wheel radius measurement in meters and inches - Wheel and gyro delta measurements - Calculation confidence metrics</p>"},{"location":"library/commands/swerve/characterization/#feedforwardcharacterization","title":"FeedforwardCharacterization","text":"<p>Determines the feedforward characterization constants for the drive motors.</p>"},{"location":"library/commands/swerve/characterization/#parameters_1","title":"Parameters","text":"<ul> <li><code>swerveDriveSubsystem</code>: The SwerveDrive subsystem instance to characterize</li> </ul>"},{"location":"library/commands/swerve/characterization/#output_1","title":"Output","text":"<p>Provides: - kS (static friction coefficient) - kV (velocity coefficient) - Data points for validation</p>"},{"location":"library/commands/swerve/characterization/#configuration-requirements","title":"Configuration Requirements","text":"<ul> <li>Clear operating space required</li> <li>Robot must be on a level surface</li> <li>Battery should be fully charged</li> <li>Robot must start in a known orientation</li> </ul>"},{"location":"library/commands/swerve/characterization/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see the Characterization Commands Javadoc</p>"},{"location":"library/commands/swerve/defaultdrive/","title":"DefaultDrive Command","text":""},{"location":"library/commands/swerve/defaultdrive/#overview","title":"Overview","text":"<p>The DefaultDrive command implements the default driving behavior for the SwerveDrive subsystem. This command provides real-time velocity control based on driver inputs through the DriveCalculator utility.</p>"},{"location":"library/commands/swerve/defaultdrive/#required-subsystems","title":"Required Subsystems","text":"<ul> <li>SwerveDriveSubsystem</li> </ul>"},{"location":"library/commands/swerve/defaultdrive/#constructor-parameters","title":"Constructor Parameters","text":"<ul> <li><code>swerveDriveSubsystem</code>: The SwerveDrive subsystem instance this command will control</li> </ul>"},{"location":"library/commands/swerve/defaultdrive/#configuration-requirements","title":"Configuration Requirements","text":"<ul> <li>No additional configuration required beyond SwerveDrive subsystem configuration in TunerConstants</li> <li>Command uses drive calculations from SwerveDrive subsystem's configured settings</li> </ul>"},{"location":"library/commands/swerve/defaultdrive/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see the DefaultDrive Javadoc</p>"},{"location":"library/commands/swerve/drivefacingangle/","title":"DriveFacingAngle Command","text":""},{"location":"library/commands/swerve/drivefacingangle/#overview","title":"Overview","text":"<p>The DriveFacingAngle command implements sophisticated angle-controlled driving capabilities, allowing the robot to maintain a specific heading while moving. This command utilizes a ProfiledPIDController for precise angle management.</p>"},{"location":"library/commands/swerve/drivefacingangle/#required-subsystems","title":"Required Subsystems","text":"<ul> <li>SwerveDriveSubsystem</li> </ul>"},{"location":"library/commands/swerve/drivefacingangle/#constructor-parameters","title":"Constructor Parameters","text":"<ul> <li><code>swerveDriveSubsystem</code>: The SwerveDrive subsystem instance this command will control</li> <li><code>targetRotation</code>: A supplier that provides the target rotation angle</li> </ul>"},{"location":"library/commands/swerve/drivefacingangle/#configuration-requirements","title":"Configuration Requirements","text":"<p>The following must be configured in TunerConstants: - PID values for angle control - Maximum angular velocity and acceleration constraints - Profile constraints for smooth angle transitions</p>"},{"location":"library/commands/swerve/drivefacingangle/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see the DriveFacingAngle Javadoc</p>"},{"location":"library/commands/swerve/drivefacingpose/","title":"DriveFacingPose Command","text":""},{"location":"library/commands/swerve/drivefacingpose/#overview","title":"Overview","text":"<p>The DriveFacingPose command implements advanced pose-relative driving capabilities, automatically orienting the robot to face a target position while maintaining normal drive control. This command utilizes sophisticated geometry calculations and PID control for precise orientation management.</p>"},{"location":"library/commands/swerve/drivefacingpose/#required-subsystems","title":"Required Subsystems","text":"<ul> <li>SwerveDriveSubsystem</li> </ul>"},{"location":"library/commands/swerve/drivefacingpose/#constructor-parameters","title":"Constructor Parameters","text":"<ul> <li><code>swerveDriveSubsystem</code>: The SwerveDrive subsystem instance this command will control</li> <li><code>targetPose</code>: A supplier that provides the target Pose2d to face towards</li> </ul>"},{"location":"library/commands/swerve/drivefacingpose/#configuration-requirements","title":"Configuration Requirements","text":"<p>The following must be configured in TunerConstants: - PID values for angle control - Maximum angular velocity and acceleration constraints - Profile constraints for smooth angle transitions</p>"},{"location":"library/commands/swerve/drivefacingpose/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see the DriveFacingPose Javadoc</p>"},{"location":"library/commands/vision/objectdetection/drivefacingbestobject/","title":"DriveFacingBestObject Command","text":"<p>A command that automatically rotates the robot to face detected game objects while allowing manual translation control. The command enables semi-automated gameplay by handling rotation while letting drivers control forward/backward and sideways movement.</p>"},{"location":"library/commands/vision/objectdetection/drivefacingbestobject/#required-subsystems","title":"Required Subsystems","text":"<ul> <li>Object Detection Subsystem</li> <li>Swerve Drive Subsystem</li> </ul>"},{"location":"library/commands/vision/objectdetection/drivefacingbestobject/#constructor-parameters","title":"Constructor Parameters","text":"<pre><code>public DriveFacingBestObject(\n    ObjectDetectionSubsystem objectDetectionSubsystem,\n    SwerveDriveSubsystem swerveDriveSubsystem,\n    GameElement... targetGameElementNames)\n</code></pre> <p>Parameters: - <code>objectDetectionSubsystem</code>: The subsystem handling object detection - <code>swerveDriveSubsystem</code>: The subsystem controlling robot movement - <code>targetGameElementNames</code>: Array of game elements to target, in priority order. The robot will face the highest-priority detected element.</p>"},{"location":"library/commands/vision/objectdetection/drivefacingbestobject/#behavior-details","title":"Behavior Details","text":"<ul> <li>Automatically rotates to face the highest-priority detected game element</li> <li>Allows full manual control of translation (forward/backward/sideways)</li> <li>Falls back to standard manual drive when no objects are detected</li> <li>Includes brief manual rotation override capability with 0.1s timeout</li> <li>Integrates with both DriveFacingPose and DefaultDrive commands</li> </ul> <p>For detailed method documentation, refer to the JavaDoc reference.</p>"},{"location":"library/commands/vision/objectdetection/pathfindtobestobject/","title":"PathfindToBestObject Command","text":"<p>A command that automatically navigates the robot to approach detected game objects. This command handles full autonomous navigation to game elements, calculating appropriate approach positions while accounting for robot dimensions.</p>"},{"location":"library/commands/vision/objectdetection/pathfindtobestobject/#required-subsystems","title":"Required Subsystems","text":"<ul> <li>Object Detection Subsystem</li> <li>Swerve Drive Subsystem</li> </ul>"},{"location":"library/commands/vision/objectdetection/pathfindtobestobject/#constructor-parameters","title":"Constructor Parameters","text":"<pre><code>public PathfindToBestObject(\n    ObjectDetectionSubsystem objectDetectionSubsystem,\n    SwerveDriveSubsystem swerveDriveSubsystem,\n    GameElement... targetGameElementNames)\n</code></pre> <p>Parameters: - <code>objectDetectionSubsystem</code>: The subsystem handling object detection - <code>swerveDriveSubsystem</code>: The subsystem controlling robot movement - <code>targetGameElementNames</code>: Array of game elements to target, in priority order. The robot will navigate to the highest-priority detected element.</p>"},{"location":"library/commands/vision/objectdetection/pathfindtobestobject/#configuration-requirements","title":"Configuration Requirements","text":"<p>The command requires proper configuration of: 1. Robot Physical Dimensions     - Bumper length and width in Constants.tunerConstants     - These dimensions are used to calculate safe approach distances</p> <ol> <li>Path Planning Parameters<ul> <li>Any PathPlanner constraints required by the swerve drive subsystem</li> <li>These affect how the robot navigates to the target position</li> </ul> </li> </ol>"},{"location":"library/commands/vision/objectdetection/pathfindtobestobject/#behavior-details","title":"Behavior Details","text":"<ul> <li>Identifies highest-priority detected game element</li> <li>Calculates optimal approach position based on:<ul> <li>Robot bumper dimensions</li> <li>Approach angle to target</li> <li>Game element position and orientation</li> </ul> </li> <li>Generates and executes path to approach position</li> <li>Command times out after 0.1 seconds but generated path continues executing</li> </ul> <p>For detailed method documentation, refer to the JavaDoc reference.</p>"},{"location":"library/subsystems/bling/","title":"Bling Subsystem","text":"<p>The Bling subsystem controls the robot's LED lighting system using the CTRE CANdle device. It provides visual feedback about robot state through different colors and animations.</p>"},{"location":"library/subsystems/bling/#constructor","title":"Constructor","text":"<pre><code>public BlingSubsystem(BlingIO io)\n</code></pre> <ul> <li><code>io</code>: The BlingIO implementation to use (either BlingIOReal for hardware or BlingIOSim for simulation)</li> </ul>"},{"location":"library/subsystems/bling/#commands-using-this-subsystem","title":"Commands Using This Subsystem","text":"<ul> <li>No Alliance Waiting Command</li> <li>Set To Alliance Color Command</li> </ul>"},{"location":"library/subsystems/bling/#configuration-requirements","title":"Configuration Requirements","text":"<ol> <li>CANdle CAN ID must be set in Constants file</li> <li>LED strip configuration in BlingConstants:<ul> <li>Number of LEDs (NUM_LEDS)</li> <li>LED strip type (LED_TYPE)</li> <li>Maximum brightness (MAX_LED_BRIGHTNESS)</li> <li>LED offset (LED_OFFSET)</li> <li>Status LED state (DISABLE_STATUS_LED)</li> </ul> </li> </ol>"},{"location":"library/subsystems/bling/#reference-documentation","title":"Reference Documentation","text":"<p>Bling Subsystem Javadoc</p>"},{"location":"library/subsystems/swerve/","title":"SwerveDrive Subsystem","text":""},{"location":"library/subsystems/swerve/#overview","title":"Overview","text":"<p>The SwerveDrive subsystem is a sophisticated drive system that enables omnidirectional movement of the robot. It manages four swerve modules (each containing drive and turn motors), handles odometry calculations, and provides autonomous path-following capabilities.</p>"},{"location":"library/subsystems/swerve/#commands-that-use-the-subsystem","title":"Commands that use the subsystem","text":"<ul> <li>DefaultDrive Command: Provides standard teleoperated control</li> <li>DriveFacingAngle Command: Maintains a specific robot heading while driving</li> <li>DriveFacingPose Command: Orients the robot to face a target position while driving</li> <li>Characterization Commands: Used for system identification and calibration</li> </ul>"},{"location":"library/subsystems/swerve/#configuration-requirements","title":"Configuration Requirements","text":""},{"location":"library/subsystems/swerve/#hardware-requirements","title":"Hardware Requirements","text":"<ol> <li>Four Swerve Drive Modules (Front Left, Front Right, Back Left, Back Right)<ul> <li>Each module requires:<ul> <li>Drive motor with encoder</li> <li>Turn motor with absolute encoder</li> </ul> </li> </ul> </li> <li>Gyroscope (NavX, Pigeon, or similar IMU)</li> </ol>"},{"location":"library/subsystems/swerve/#configuration-in-tunerconstants","title":"Configuration in TunerConstants","text":"<p>All configuration is handled through TunerConstants, including: - Module configurations (gear ratios, conversions, PID values) - PathPlanner settings - Holonomic drive controller settings - Module positions and dimensions - Maximum velocity and acceleration limits - Drive characterization values (kS, kV, kA) - Wheel radius parameters - Absolute encoder offsets</p> <p>See the JavaDoc Reference for detailed configuration options.</p>"},{"location":"library/subsystems/swerve/#additional-notes","title":"Additional Notes","text":"<ul> <li>Odometry updates run on a separate high-frequency thread</li> <li>Vision measurements can be incorporated for pose estimation</li> <li>Supports both teleop and autonomous operation</li> <li>PathPlanner integration for autonomous path following</li> <li>Built-in system identification capabilities for tuning</li> </ul>"},{"location":"library/subsystems/vision/apriltag/","title":"AprilTag Subsystem","text":""},{"location":"library/subsystems/vision/apriltag/#overview","title":"Overview","text":"<p>The AprilTag subsystem is responsible for detecting and processing AprilTag fiducial markers using PhotonVision cameras. It provides robust pose estimation with statistical confidence measures by processing data from multiple cameras simultaneously.</p>"},{"location":"library/subsystems/vision/apriltag/#features","title":"Features","text":"<ul> <li>Multi-camera AprilTag detection and processing</li> <li>Statistical confidence calculations for pose estimates</li> <li>Automatic rejection of unreliable measurements</li> <li>Comprehensive logging of accepted and rejected poses</li> <li>Camera connection monitoring with alerts</li> </ul>"},{"location":"library/subsystems/vision/apriltag/#constructor-parameters","title":"Constructor Parameters","text":"<p>The AprilTag subsystem requires two main parameters:</p> <ol> <li> <p><code>AprilTagConsumer consumer</code>: A functional interface that receives processed AprilTag data, including:</p> <ul> <li>Robot pose in field coordinates</li> <li>Timestamp of the measurement</li> <li>Statistical confidence measures (standard deviations)</li> </ul> </li> <li> <p><code>AprilTagIO... io</code>: Variable number of AprilTagIO interfaces, one for each camera</p> </li> </ol>"},{"location":"library/subsystems/vision/apriltag/#commands-that-use-this-subsystem","title":"Commands That Use This Subsystem","text":"<p>Currently there are no direct commands using this subsystem. The subsystem primarily acts as a data provider for other systems through its consumer interface.</p>"},{"location":"library/subsystems/vision/apriltag/#required-configuration","title":"Required Configuration","text":"<ol> <li> <p>Camera Configuration:</p> <ul> <li><code>CAMERA_CONFIGS</code> array must be defined in AprilTagConstants</li> <li>Each camera must have proper configuration settings</li> </ul> </li> <li> <p>Statistical Parameters:</p> <ul> <li><code>CAMERA_STD_DEV_FACTORS</code>: Must be &gt;= 1.0 for each camera</li> <li><code>LINEAR_STD_DEV_BASE</code>: Base value for linear measurement standard deviation</li> <li><code>ANGULAR_STD_DEV_BASE</code>: Base value for angular measurement standard deviation</li> </ul> </li> <li> <p>Field Layout:</p> <ul> <li><code>APRIL_TAG_LAYOUT</code>: Must contain the field's AprilTag layout configuration</li> <li>Field dimensions must be properly configured</li> </ul> </li> <li> <p>Processing Parameters:</p> <ul> <li><code>MAX_AMBIGUITY</code>: Maximum allowed pose ambiguity for single-tag detections</li> <li><code>MAX_Z_ERROR</code>: Maximum allowed Z-coordinate error</li> </ul> </li> </ol>"},{"location":"library/subsystems/vision/apriltag/#additional-information","title":"Additional Information","text":"<p>The subsystem includes several safeguards for reliable operation: - Automatic rejection of poses outside field boundaries - Filtering of high-ambiguity single-tag detections - Distance-based confidence scaling - Camera disconnect detection and alerts</p>"},{"location":"library/subsystems/vision/apriltag/#related-links","title":"Related Links","text":"<ul> <li>JavaDoc Reference</li> <li>PhotonVision Documentation</li> </ul>"},{"location":"library/subsystems/vision/objectdetection/","title":"Object Detection Subsystem","text":"<p>The Object Detection subsystem is a vision processing system that uses PhotonVision to detect and track game objects on the field in real-time. It maintains lists of both stable (consistently tracked) and pending (newly detected) objects, providing filtered and reliable object detection data to other subsystems.</p>"},{"location":"library/subsystems/vision/objectdetection/#constructor","title":"Constructor","text":"<pre><code>public ObjectDetectionSubsystem(Supplier&lt;Pose2d&gt; robotPose, ObjectDetectionIO... io)\n</code></pre> <p>Parameters: - <code>robotPose</code>: A supplier function that provides the current robot pose in field coordinates - <code>io</code>: One or more ObjectDetectionIO interfaces representing the vision cameras</p>"},{"location":"library/subsystems/vision/objectdetection/#related-commands","title":"Related Commands","text":"<p>The following commands utilize this subsystem: - DriveFacingBestObject - Automatically rotates the robot to face detected objects while driving - PathfindToBestObject - Autonomously navigates the robot to approach detected objects</p>"},{"location":"library/subsystems/vision/objectdetection/#configuration-requirements","title":"Configuration Requirements","text":"<p>The subsystem requires several constants to be configured in the ObjectDetectionConstants class:</p> <ol> <li> <p>Camera Configurations:</p> <ul> <li><code>CAMERA_CONFIGS</code>: Array of camera configuration parameters</li> <li><code>POSITION_MATCH_TOLERANCE</code>: Distance threshold for matching detected objects</li> <li><code>HISTORY_LENGTH</code>: Number of frames to keep in detection history</li> <li><code>REQUIRED_DETECTIONS</code>: Number of detections required for stability</li> <li><code>MISSING_FRAMES_THRESHOLD</code>: Number of missed frames before losing stability</li> </ul> </li> <li> <p>Game Element Definitions:</p> <ul> <li><code>GAME_ELEMENTS</code>: Array mapping detected class IDs to game elements</li> </ul> </li> <li> <p>PhotonVision Configuration:</p> <ul> <li>Each camera must be properly configured in PhotonVision with:<ul> <li>Appropriate pipelines for object detection</li> <li>Correct camera mounting position and angle</li> <li>Calibrated camera parameters</li> </ul> </li> </ul> </li> </ol>"},{"location":"library/subsystems/vision/objectdetection/#requirements","title":"Requirements","text":"<ul> <li>PhotonVision installed and configured on your robot</li> <li>At least one compatible camera connected and configured</li> <li>WPILib 2024 or newer</li> </ul> <p>For detailed method documentation, refer to the JavaDoc reference.</p>"}]}